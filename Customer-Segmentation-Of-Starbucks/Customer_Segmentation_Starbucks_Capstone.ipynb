{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "* We will be exploring the Starbuckâ€™s Dataset which simulates how people make purchasing decisions and how those decisions are influenced by promotional offers. \n",
    "* There are three **offers_types** that can be sent: buy-one-get-one (BOGO), discount, and informational. \n",
    "* We will segment the customer data on different parameters and check its behavious on different **offer_tyoes** using both supervised and unsupervised learning\n",
    "* We will analyse the data in the Exploratory Data Analysis part of this section and answer the following questions related to customer segmentation and its buying behavious.\n",
    "\n",
    "\n",
    "- 1. What is the Gender Distribution of Starbucks Customers?\n",
    "- 2. What is the Age Distribution and average age of Starbucks Customers?\n",
    "- 3. What is the Income Distribution and average Income of Starbucks Customers?\n",
    "- 4. How many customers enrolled yearly?\n",
    "- 5. Which gender has the highest yearly membership?\n",
    "- 6. Which gender has the highest Annual income?\n",
    "- 7. What is the distribution of event  in  transcripts?\n",
    "- 8. What is the percent of trasactions and offers in the event?\n",
    "- 9. What are the types of offers : received,views, completed ?\n",
    "- 10. What is the Income Distribution for the Offer Events?\n",
    "- 11. What are the Offer types amongst ages, gender and income groups?\n",
    "- 12. What is the highest completed offer?\n",
    "- 13. What is the lowest completed offer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Data Preparation\n",
    "#### 2.Data understanding\n",
    "#### 3.Cleaning the data\n",
    "#### 4.Exploratory Data Analysis\n",
    "#### 5.Data Modelling ( Unsupervised ans Supervised Learning)\n",
    "#### 6.Hyper parameter tuning\n",
    "#### 7.Evalute the model accuracy\n",
    "#### 8.Conclusion\n",
    "#### 9.Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding\n",
    "The data is provided by Starbucks with three files containing the following information:\n",
    "* 3 .json files.\n",
    "    * portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "    * profile.json - demographic data for each customer\n",
    "    * transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - time for offer to be open, in days\n",
    "* channels (list of strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since start of test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning each dataset\n",
    "we will go though the each data diles and clean them and convert them into the formats to use the data for futhur analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the id columns of every dataset to its respective tags to avoid confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the id columns for ease of understanding\n",
    "portfolio.rename(columns={\"id\":\"offer_id\"}, inplace=True)\n",
    "profile.rename(columns={\"id\":\"customer_id\"}, inplace=True)\n",
    "transcript.rename(columns={\"person\":\"customer_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Portfolio Data:\n",
    "\n",
    "- One-hot encode channels\n",
    "- One-hot encode offer_type column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that the portfolio dataset consists of 10 not-null entries that contains information about the offers provided by starbucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a histogram containing a distribution of 3 types of offers in 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# One-hot encode : channels column\n",
    "channels = portfolio[\"channels\"].str.join(sep=\"*\").str.get_dummies(sep=\"*\")\n",
    "    \n",
    "# One-hot encode : offer_type column\n",
    "offer_type = pd.get_dummies(portfolio['offer_type'])\n",
    "    \n",
    "# Concat one-hot into a portfolio_df\n",
    "portfolio_df = pd.concat([portfolio, channels, offer_type], axis=1, sort=False)\n",
    "\n",
    "# Remove channels and offer_type\n",
    "portfolio = portfolio_df.drop(['channels'], axis=1)\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Profile Data\n",
    "- Check for null values\n",
    "- check the age column for extreme values (118)\n",
    "- Drop rows with no gender, income, age of 118\n",
    "- Create readable date format in became_member_on column\n",
    "- Extract its year from became_member_on column add start_year columns (for further analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have age as 118 which isnt practical ans is an outlier value. Lets check the count of 118 values in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile.where(profile.age==118).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2175 null values in gender and income columns and age column has 118 has  2175 values. \n",
    "Since we have the same number of null values and 118 are same these columns, we need to check do they lie in the same row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if NaN values for  gender & income and 118 value of age columnalways occur in same rows\n",
    "profile[(profile.age == 118) & (profile.gender.isnull()) & (profile.income.isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These NaN values and 118  occur in the same rows, resulting in 2,175 out of 17,000 customers without any demographic data. \n",
    "There wont be any means to keep this data which could hamper the accuracy of the model,\n",
    "Although this means dropping more than 10 percent of the customer data, We will have to drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile: drop rows with no gender, income, age data\n",
    "profile = profile.drop(profile[profile['gender'].isnull()].index)\n",
    "profile.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, cleared all the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "profile.became_member_on = pd.to_datetime(profile.became_member_on, format = '%Y%m%d')\n",
    "profile['start_year'] = profile.became_member_on.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Transcript Data\n",
    "\n",
    "- Create separate columns for amount and offer_id from value column dictionary\n",
    "- merge the three datasets with common columns\n",
    "- transcript: segregate offer and transaction data \n",
    "- Label the columns - offer_id. offer_type, gender, and the unique customer_ids to convert them into integer data tpe\n",
    "- Create a offers dataframe by seperating it from transaction in the event column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to create offer id and amount columns from the transcript table.\n",
    "def create_offer_id_column(val):\n",
    "    if list(val.keys())[0] in ['offer id', 'offer_id']:\n",
    "        return list(val.values())[0]\n",
    "    \n",
    "def create_amount_column(val):\n",
    "    if list(val.keys())[0] in [\"amount\"]:\n",
    "        return list(val.values())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create separate columns for amount and offer_id and reward from value col dictionary.\n",
    "transcript['offer_id'] = transcript.value.apply(create_offer_id_column)\n",
    "transcript['amount'] = transcript.value.apply(create_amount_column)\n",
    "\n",
    "\n",
    "# change amount and reward column type to float\n",
    "transcript.amount.astype('float')\n",
    "transcript.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transcript.drop(columns=['value'], inplace=True)\n",
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the three data sets with common columns into one for futhur analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge the transcript and profile dataframes on customer_id column\n",
    "transcript = transcript.merge(profile, on=['customer_id'])\n",
    "transcript.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the transcript and portfolio  on customer_id column using left join\n",
    "# To maintain all the offer_ids from the transcript column\n",
    "transcript = transcript.merge(portfolio, on=['offer_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Labelling\n",
    "- Label the columns - offer_id. offer_type, gender, and the unique customer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Label Encoding the category columns- \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#label encoding - offer_id (10 different IDs) from the portfolio data set\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(portfolio.offer_id)\n",
    "transcript['offer_id'] = le1.fit_transform(transcript['offer_id'].astype(str))\n",
    "\n",
    "\n",
    "#label encoding - offer_type from the portfolio data set (3 different types, bogo-discount-informational)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(portfolio.offer_type)\n",
    "transcript['offer_type'] = le2.fit_transform(transcript['offer_type'].astype(str))\n",
    "\n",
    "\n",
    "# label encoding for gender from the profile data set(4 different types, male-female-other)\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le3.fit(profile.gender)\n",
    "transcript['gender'] = le3.fit_transform(transcript['gender'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#To retrive its original value we can use its inverse function\n",
    "le3.inverse_transform([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the unique customer ids, create a mapper function to avoid duplication.\n",
    "def id_label(customer_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    Description:\n",
    "    This function will label ;ong values of customer_ids '912b9f623b9e4b4eb99b6dc919f09a93' to unique integers.\n",
    "    \n",
    "    INPUT: \n",
    "    customer_id (str): transcript column to be labeled whose values are to be changed\n",
    "    \n",
    "    OUTPUT:\n",
    "    coded_id (list): list of the labelled integers for each value\n",
    "     \n",
    "    \"\"\"\n",
    "    coded_dict = dict()\n",
    "    counter = 1\n",
    "    col_name=str(customer_id)\n",
    "    coded_id = []\n",
    "    \n",
    "    for val in transcript[customer_id]:\n",
    "        try: \n",
    "            if isinstance(val, str):\n",
    "                if val not in coded_dict:\n",
    "                    coded_dict[val] = counter\n",
    "                    counter+=1\n",
    "\n",
    "                coded_id.append(coded_dict[val])\n",
    "            else:\n",
    "                coded_dict[val] = np.nan\n",
    "                coded_id.append(coded_dict[val])\n",
    "        except:\n",
    "            pass\n",
    "    del transcript[customer_id]\n",
    "    return coded_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript['customer_id'] = id_label(\"customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript.customer_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a offers dataframe by seperating it from transaction in the event column\n",
    "- Offer dataframe consist of all the offer types- offer_received, offer_viewed, offer_completed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seperate the three offer columns from the transaction column\n",
    "transaction_df = transcript[transcript.event == \"transaction\"]\n",
    "transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seperate the three offer columns from the transaction column\n",
    "offers_df = transcript[transcript.event != \"transaction\"]\n",
    "offers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Analysis:\n",
    "\n",
    "- 1. What is the Gender Distribution of Starbucks Customers?\n",
    "- 2. What is the Age Distribution and average age of Starbucks Customers?\n",
    "- 3. What is the Income Distribution and average Income of Starbucks Customers?\n",
    "- 4. How many customers enrolled yearly?\n",
    "- 5. Which gender has the highest yearly membership?\n",
    "- 6. Which gender has the highest Annual income?\n",
    "- 7. What is the distribution of event  in  transcripts?\n",
    "- 8. What is the percent of trasactions and offers in the event?\n",
    "- 9. What are the types of offers : received,views, completed ?\n",
    "- 10. What is the Income Distribution for the Offer Events?\n",
    "- 11. What are the Offer types amongst ages, gender and income groups?\n",
    "- 12. What is the highest completed offer?\n",
    "- 13. What is the lowest completed offer?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques: 1 What is the Gender Distribution of Starbucks Customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Subplots for distribution based on Gender,Age,Income and start year of membership for the cleaned Profile data\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 12))\n",
    "fig.suptitle('Demographics of Customer Data of Starbucks', fontsize=15, weight='bold')\n",
    "\n",
    "# GENDER BASED SUBPLOT\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(profile['gender']);\n",
    "plt.style.use('seaborn');\n",
    "plt.title('Gender Distribution of Starbucks Customers');\n",
    "plt.xlabel(\"Gender\");\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "\n",
    "# AGE BASED SUBPLOT\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(profile['age']);\n",
    "plt.style.use('seaborn')\n",
    "plt.title(\"Age Distribution of Starbucks Customers\" );\n",
    "plt.xlabel(\"Age\");\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "# INCOME BASED  SUBPLOT\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(profile['income'] * 1E-3 );\n",
    "plt.style.use('seaborn')\n",
    "plt.title(\"Income Distribution of Starbucks Customers\");\n",
    "plt.xlabel(\"Income\");\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "\n",
    "# BECAME A MEMBER OF STARBUCKS ON(YEAR) SUBPLOT\n",
    "plt.subplot(2, 2, 4)\n",
    "profile[\"start_year\"].value_counts().plot(kind = 'bar'); \n",
    "plt.style.use('seaborn')\n",
    "plt.title(\"Became a member of Starbucks Customers in the year\");\n",
    "plt.xlabel(\"Yearly Membership\");\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans1: The proprtion of males(around 9000) is slightly more than those of the females(around 6000)and very small amount of others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques2. What is the Age Distribution and average age of Starbucks Customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile['age'].describe()['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans2: Age group range from 40-70 frequently visit starbucksrbucks, the reason can be steady life after 40.\n",
    "- with an average of 54 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques3: What is the Income Distribution and average Income of Starbucks Customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile['income'].describe()['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans 3: There is a decrease in the number of customers as after 70K, \n",
    "    mentioning as the income increases people spend less on coffe.\n",
    "- with an average income of 65k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques4. How many customers enrolled yearly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile[\"start_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans4: Members of the starbucks increased exponentially from 2013 and reached its highest in 2017 which later declines steadily\n",
    "- 5599 customers enrolled in 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques5 : Which gender has the highest yearly membership? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# groupby start_year and gender to plot a graph\n",
    "membership_year = profile.groupby(['start_year', 'gender'])[\"age\"].count().reset_index()\n",
    "membership_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot a bar graph for membership program as a function of gender \n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.barplot(x='start_year', y='age', hue='gender', data=membership_year);\n",
    "plt.xlabel('Membership Start Year',fontsize = 12);\n",
    "plt.ylabel('Count',fontsize = 12);\n",
    "plt.title(\"Gender distribution of yearly membership\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans5: With the increase in popularity of starbucks, people have joined starbucks yerly exponentially and reached its zenith in 2017.\n",
    "- more men have joined than the female and very few from others every year. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques6 :Which gender has the highest Annual income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "sns.violinplot(x=profile['gender'], y=profile['income'])\n",
    "plt.title('Gender distribution of Annual Income')\n",
    "plt.ylabel('Income')\n",
    "plt.xlabel('Gender')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The highest and the lowest income for both male and female are approximately same and for others it is less on both the sides.\n",
    "- The median income (the white dot) for females (around **70k**) is higher than males and others (around **60k)**\n",
    "- for females the income spreads from **40k** to **100k**. \n",
    "- For males most the spread is around **40k** to **70k** which close to median.\n",
    "- for others the spread is around **60K**\n",
    "- The count of male customers in low-income level is slightly higher than that of female  and other customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = portfolio[\"offer_type\"].value_counts().plot.bar(figsize=(5,5),fontsize=14,)\n",
    "ax.set_title(\"What are the offer types?\", fontsize=20)\n",
    "ax.set_xlabel(\"Offers\", fontsize=15)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=15)\n",
    "sns.despine(bottom=True, left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques7: What is the distribution of event  in  transcripts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(transcript['event'])\n",
    "plt.title('Number of events In Transcripts')\n",
    "plt.ylabel('Number of Transcripts')\n",
    "plt.xlabel('Transcript type')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans7: We can see that most of the transcripts are transactions. \n",
    "- Around **75%** of the offer received were viewed. And nearly **50%** of the viewed offers were completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques8: What is the percent of trasactions and offers in the event?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_counts = transcript['event'].value_counts()\n",
    "event_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tranaction percent and offer percent\n",
    "\n",
    "transactions_percent = 100 * event_counts[0] / event_counts.sum()\n",
    "offers_percent = 100 * event_counts[1:].sum() / event_counts.sum()\n",
    "\n",
    "(transactions_percent, offers_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans 8: Nearly 45.5% are trasactions and 54.5% are offers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques9: What are the types of  offers  : received,views, completed ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_df.event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_received = offers_df[offers_df[\"event\"] == \"offer received\"]\n",
    "offer_viewed = offers_df[offers_df[\"event\"]== \"offer viewed\"]\n",
    "offer_completed = offers_df[offers_df[\"event\"] == \"offer completed\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of membership days grouped by success\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('Offer types : received, viewed and completed', fontsize=15, weight='bold')\n",
    "\n",
    "# Subplot for bogo offers\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.countplot(x=offer_received['offer_type'])\n",
    "plt.title('Number of types of offers received ', fontsize=13)\n",
    "plt.xlabel('Offer Received')\n",
    "plt.xticks(rotation = 45, fontsize=13)\n",
    "\n",
    "\n",
    "# Subplot for discount offers\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.countplot(x=offer_viewed['offer_type'])\n",
    "plt.title('Number of Viewed Promotions for each Offer', fontsize=13)\n",
    "plt.xlabel('Offer Viewed')\n",
    "plt.xticks(rotation = 45, fontsize=13)\n",
    "\n",
    "# Subplot for informational offers\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.countplot(x=offer_completed['offer_type'])\n",
    "plt.title('Number of Viewed Promotions for each Offer', fontsize=13)\n",
    "plt.xlabel('Offer Completed')\n",
    "plt.xticks(rotation = 45, fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le2.inverse_transform([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans9: More of Bogo and Dicount offers were received by the customers than that of informational.\n",
    "- More Bogo offers have been viewed\n",
    "- Most of the discount offers have been completed and no informational offer completed.\n",
    "- Hence, in order to make a offer complete, more of discount offers must be sent to the customers.\n",
    "- Here, bogo has also been a good offer since high number of customers view such offers.m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques10: What is the Income Distribution for the Offer Events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create a age group Column cleaning by  segregation\n",
    "offers_df['age_groups'] = pd.cut(offers_df.age, bins=[11, 20, 30, 40, 50, 60, 70, 80, 110], \n",
    "                               labels=['11-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80+'])\n",
    "\n",
    "\n",
    "#Create a Income group Column cleaning by  segregation\n",
    "offers_df['income_groups'] = pd.cut(x=profile[\"income\"],\n",
    "                                    bins=[30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000,  120000],\n",
    "                                   labels =['30-40K','40-50K','50-60K','60-70K','70-80K','80-90K','90-100K','100-110K','110-120K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.countplot(x=offers_df['income_groups'], hue=\"event\", data=offers_df)\n",
    "plt.title(\"Income Distribution for the Offer Events\")\n",
    "plt.ylabel('Total')\n",
    "plt.xlabel('Income ')\n",
    "plt.xticks(rotation = 30)\n",
    "plt.legend(title='Offer Event')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ans10:** Highest Offer is received by income group of 50-60k with the least of 110-120k.\n",
    "- The highest offer completed is also from 50-60k and decreses on either side with a larger slope on the higher income groups.\n",
    "- starbucks have  lesser higher income group customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(13, 12))\n",
    "fig.suptitle('Offer types amongst ages, gender and income groups', fontsize=18, weight='bold')\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=1.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#fig.tight_layout(pad=5.0)\n",
    "plt.subplot(3, 1, 1)\n",
    "#plt.figure(figsize=(14, 5))\n",
    "sns.countplot(x=\"age_groups\", hue=\"offer_type\", data=offers_df);\n",
    "plt.ylabel('Total',fontsize=15);\n",
    "plt.xlabel('Age Group',fontsize=15);\n",
    "plt.xticks(rotation = 0);\n",
    "plt.legend(title='Offer Type');\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.countplot(x=offers_df['gender'], hue = 'offer_type', data=offers_df);\n",
    "plt.ylabel('Total',fontsize=15);\n",
    "plt.xlabel('Gender',fontsize=15);\n",
    "plt.xticks(rotation = 0);\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.countplot(x=offers_df['income_groups'], hue = 'offer_type', data=offers_df)\n",
    "plt.ylabel('Total',fontsize=15)\n",
    "plt.xlabel('Income Group',fontsize=15)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le2.inverse_transform([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le3.inverse_transform([0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ans11:** We can see from the above graphs that, Bogo is slightly more popular amongst the ages,gender and income groups.\n",
    "- 50-59 age group is more respondent to these offers than the otherer groups\n",
    "- Also, for the income distribution, the informational offer is almost round 50% than the other two.\n",
    "- Most male are respondents of these offers than the females with BOGO its leading type\n",
    "- To sumup it up,  the active starbucks customer respondents are from the age group of 50-59, with higher male percentage having and annual income of 50-60k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed_off_count = transcript[transcript['event'] == 'offer completed']\n",
    "plt.figure(figsize=(14, 5))\n",
    "offer_completed = offers_df[offers_df[\"event\"] == \"offer completed\"]\n",
    "sns.countplot(y=offer_completed['offer_id'])\n",
    "plt.title('Number of Completed offers for each Offer')\n",
    "plt.ylabel('Offer ID')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques 12: What is the highest completed offer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Completion: {}\" .format(offer_completed.offer_id.value_counts().values[0]))\n",
    "print(\"Offer ID with maximum offers completed:{}\".format(offer_completed.offer_id.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "le1.inverse_transform([9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans12: Out of the orders completed,The offer_id which was a gained higher success rate is 'fafdcd668e3743c1bb461111dcafc2a4'\n",
    "- with a total of 4957 completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ques13:What is the lowest completed offer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Completion: {}\" .format(offer_completed.offer_id.value_counts().values[-1]))\n",
    "print(\"Offer ID with minimum offers completed:{}\".format(offer_completed.offer_id.value_counts().index[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1.inverse_transform([4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ans13: Out of the orders completed,The offer_id which was a gained least success rate is '4d5c57ea9a6940dd891ad53e9dbe8da0'\n",
    "- with a total of 3281 completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping these columns because with null values, datetime,object,category datatypes\n",
    "cols_to_drop = ['age_groups','income_groups','amount','became_member_on' ,'event']\n",
    "offers_df = offers_df.drop(columns= cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling\n",
    "#### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "wss = [] #within the sum of squares\n",
    "for k in range(1,11): #take the range of Kvalues 1-10\n",
    "    kmeans = KMeans(n_clusters=k, init=\"k-means++\")\n",
    "    kmeans.fit(offers_df) #Fit the subset of data\n",
    "    wss.append(kmeans.inertia_) #inertia_ : Sum of squared distances of samples to their closest cluster center.\n",
    "\n",
    "#Plot the Figure\n",
    "plt.figure(1, figsize=(14,5))\n",
    "plt.plot(range(1,11), wss, color='green', linewidth=2.0 , marker = \"o\")\n",
    "plt.xlabel(\"K values\")\n",
    "plt.ylabel(\"wss (Within Sum of square)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Graph makes an elbow at 2.\n",
    "- Number of optimal clusters for the dataset is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the number of clusters as 2\n",
    "kmodel = KMeans(n_clusters=2,random_state=10)\n",
    "#Fit the model to predict the labels\n",
    "cluster_labels =kmodel.fit_predict(offers_df) \n",
    "cluster_labels #view the labels of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_df[\"cluster\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check the centroids for the above cluster model\n",
    "kmodel.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(15, 10))\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=1.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "fig.tight_layout()\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.countplot(x=\"income\", hue=\"offer_type\", data=offers_df[cluster_labels==0]);\n",
    "plt.title('K-Means Clustering of cluster labels 1',fontsize=15);\n",
    "plt.ylabel('Total');\n",
    "plt.xlabel('Income');\n",
    "plt.xticks(rotation = 45,fontsize= 15);\n",
    "plt.legend(title='Offer Type');\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.countplot(x=\"income\", hue=\"offer_type\", data=offers_df[cluster_labels==1]);\n",
    "plt.title('K-Means Clustering of cluster labels 2',fontsize=15);\n",
    "plt.ylabel('Total');\n",
    "plt.xlabel('Income');\n",
    "plt.xticks(rotation = 45, fontsize= 15);\n",
    "plt.legend(title='Offer Type');\n",
    "\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compared to BOGO and Discount offer, the informational offers are very less popular.\n",
    "- Few cases the Discout Offers are used more than the BOGO offers:\n",
    "- In **cluster1** at income=51000, income=52000  and\n",
    "- In **cluster2** at income=76000, income=77000\n",
    "- Since the income is unevenly distributed,it can also be concluded that the annual income is indepedent of the purchasing behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph to find Most Popular Offers Type Gender wise for cluster 1\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 10))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.countplot(x=\"gender\", hue=\"offer_type\", data=offers_df[cluster_labels==0])\n",
    "plt.title('K-Means Clustering for cluster 1 ')\n",
    "plt.ylabel('Total')\n",
    "plt.xlabel('Gender')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.legend(title='Offer Type')\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.countplot(x=\"gender\", hue=\"offer_type\", data=offers_df[cluster_labels==1])\n",
    "plt.title('K-Means Clustering for cluster 2')\n",
    "plt.ylabel('Total')\n",
    "plt.xlabel('Gender')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.legend(title='Offer Type')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Income Range for Cluster 1:\", offers_df[cluster_labels==0]['income'].min(), \n",
    "      \"to\", offers_df[cluster_labels==0]['income'].max())\n",
    "\n",
    "print(\"Income Range for Cluster 2:\", offers_df[cluster_labels==1]['income'].min(), \n",
    "      \"to\", offers_df[cluster_labels==1]['income'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Compared to BOGO and Discount offer, the informational offers are less popular.\n",
    "-  For **Cluster 1**, the income ranges from 30000.0 to 68000.0. \n",
    "-  It can thus be concluded  that Males with the above income range tend to spend more than Females and Other Genders for the BOGO and Discount Offers.\n",
    "-  For **Cluster 2**, the income ranges from 69000.0 to 120000.0. \n",
    "-  It can thus be concluded  that Females with income range 71000.0 to 120000.0 tend to spend more than Males and Other Genders for the BOGO and Discount Offers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "#### The target column is offer_type.  It will help to predict the correct offer_type to send to each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data into Target and Features variables\n",
    "\n",
    "target = offers_df['offer_type']\n",
    "features = offers_df.drop(columns=['offer_type', 'customer_id', 'offer_id','cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and testing sets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target,test_size=0.2, random_state=10)\n",
    "\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics:\n",
    "- Since it is a classification problem,\n",
    "- we will use accuracy to evaluate my models.\n",
    "- Comapre the correct predictions and total number of predicitons to determine the accuracy of the model and choose the best.\n",
    "- **Five different ML algorithms** can be test on the datset :  \n",
    "1. Decision Trees  \n",
    "2. Logistic Regression  \n",
    "3. Nearest Neighbours (KNN)  \n",
    "4. Naive Bayes  \n",
    "5. Random Forest  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    Description: Train the dataset and predict its accuracy using differnt ML algorithms\n",
    "              for testing take first 300 training samples (X_train[:300],y_train[:300])\n",
    "    INPUT:\n",
    "       - model: the learning algorithm to be trained and predicted\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    OUTPUT:\n",
    "        - Accuracy Scores and F Scores of the models\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "   \n",
    "    # Predict on the X_test,\n",
    "    predictions_test =model.predict(X_test)\n",
    "    \n",
    "    # Predict on the first 300 training samples(X_train)\n",
    "    predictions_train = model.predict(X_train[:300]) \n",
    "    \n",
    "    # Accuracy on  y_train[:300]\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # Accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # F-score on y_train[:300]  using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta = 0.5, average='weighted') # average = weighted because multiclass classification\n",
    "        \n",
    "    #  F-score on  y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta = 0.5, average='weighted')\n",
    "       \n",
    "    print(\"{} trained.\".format(model.__class__.__name__))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "\n",
    "lr = LogisticRegression(random_state=10)\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "knn = KNeighborsClassifier()\n",
    "gnb = GaussianNB() \n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Collect results on the models\n",
    "results = {}\n",
    "for model in [lr, rf, knn, gnb, dt]:\n",
    "    model_name = model.__class__.__name__\n",
    "    results[model_name] = {}\n",
    "    results[model_name] = train_predict(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in results.items():\n",
    "    print (i[0])\n",
    "    display(pd.DataFrame(i[1], index=range(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy score is 100% for  training and testing datasets for **RandomForestClassifier,GaussianNB,DecisionTreeClassifier** which can lead to **overfitting.\n",
    "- Since logistic Regression has a very low train accuracy of 0.50 and test accuracy of 0.52.\n",
    "- So, we choose **KNeighborsClassifier.**\n",
    "- It has good results **0.93 on training and 0.82 on testing datasets.**\n",
    "- Since we have few binomial outcomes ( BOGO = 1, discount = 2, informational = 3 ) we can use  **KNeighborsClassifier.**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning of KNeighborsClassifier to increase the acuuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is possible to **improve the performance of the model** from it base instance by **tuning hyperparameters** of that algorithm.\n",
    "- We will define **a range of values** that would be evaluated in the hyper parameter space of the for **KNeighborsClassifier** model using **RandomizedSearchCV.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly assign the values to the parameters\n",
    "para_grid = {\"n_neighbors\" :list(range(20,30)), \n",
    "             \"leaf_size\" :list(range(1,6)),\n",
    "             \"p\" : [1,2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn_randomcv = RandomizedSearchCV(estimator= knn, param_distributions= para_grid , n_iter=10, cv=3, \n",
    "                                  verbose=2,random_state=100,n_jobs=-1)\n",
    "knn_randomcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best parameter values\n",
    "best_parameters = knn_randomcv.best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model with best parameters\n",
    "train_predict(KNeighborsClassifier(leaf_size=4, n_neighbors=21, p=1),X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best scores achieved after tuning,its essential hyper-parameters{'p': 1, 'n_neighbors': 21, 'leaf_size': 4} byKNeighborsClassifier : **training accuracy : 0.93 and testing accuracy :0.93**  .\n",
    "- testing accuracy has increased after hyperparameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute the model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets pick a random customer from our data n test its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.iloc[27275,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.iloc[27275]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le2.inverse_transform([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above taken cutsomer has responded to **BOGO** type of offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets evaluate our model to check its accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have the customer data with the above features we would be able to preduct its offer type using our above tested model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = [588, 1.0, 51.0, 61000.0, 2015, 10.0, 10.0, 7.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(leaf_size=4, n_neighbors=21, p=1)\n",
    "clf.fit(features, target)\n",
    "clf.score(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.predict([customer_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model has correctly predicted that the customer will likely respond tor **BOGO offer** type with an **accuracy of 93 %.**\n",
    "- Hence our model has good accuracy for prediction,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "### Segmentation of startbucks Customers:\n",
    "- The customers can be segmented depending on various parameters according to the campaign chosen\n",
    "- On analysis the data using supervised and unsupervised learning(Kmeans), we can conclude that:\n",
    "- Different segments of customers react to offers differently.\n",
    "- The count of male customers in low-income level is slightly higher than that of female and other customers\n",
    "- Though the aveage salary of femal is greater than that of the male, female spend less on starbucks than male\n",
    "- Starbucks has more of the young crowd than those of the aged once.\n",
    "- The result of the offer_type was prediced by training a supervised classifier. \n",
    "\n",
    "## Results:- \n",
    "- Customers are attracted to **BOGO and Discount** offers more as compared to Informational Offers\n",
    "- **The buying behaviour of a customer is indepemdent of its annual income**\n",
    "- **Starbucks have more male customers than females and other gender.**\n",
    "- **KNeighborsClassifier** turned out to be the best algorithm for this task and predicts customer response with an accuracy rate of almost 93% after hyperarameter tuning. Given the fact that also the same customer will react differently the same offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
